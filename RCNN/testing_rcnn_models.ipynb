{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oDph2GVniwCK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy.core.defchararray import join, mod\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import os\n",
        "import torch\n",
        "from torch._C import device\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, fasterrcnn_mobilenet_v3_large_fpn,fasterrcnn_resnet50_fpn_v2\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from PIL import Image\n",
        "from torchvision import transforms as torchtrans\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "c7AQHVEti97P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_img(image_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        img_res = img_rgb/255\n",
        "        img_res = torch.as_tensor(img_res).to(device)\n",
        "        img_res = img_res.permute(2, 0, 1)\n",
        "        return img_res\n",
        "\n",
        "def apply_nms(orig_prediction, iou_thresh=None):\n",
        "\n",
        "\n",
        "   # torchvision returns the indices of the bboxes to keep\n",
        "   keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "\n",
        "\n",
        "   final_prediction = orig_prediction\n",
        "   final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "   final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "   final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "\n",
        "\n",
        "   return final_prediction\n",
        "\n",
        "\n",
        "# function to convert a torchtensor back to PIL image\n",
        "def torch_to_pil(img):\n",
        "   return torchtrans.ToPILImage()(img).convert('RGB')\n",
        "\n",
        "\n",
        "def plot_img_bbox(img, target):\n",
        "   # plot the image and bboxes\n",
        "   # Bounding boxes are defined as follows: x-min y-min width height\n",
        "   fig, a = plt.subplots(1, 1)\n",
        "   fig.set_size_inches(5, 5)\n",
        "   a.imshow(img)\n",
        "\n",
        "\n",
        "   # Detach the tensor before using it in numpy()\n",
        "   for box in target['boxes'].detach().cpu().numpy():\n",
        "       x, y, width, height = box[0], box[1], box[2] - box[0], box[3] - box[1]\n",
        "       rect = patches.Rectangle((x, y),\n",
        "                                width, height,\n",
        "                                linewidth=2,\n",
        "                                edgecolor='r',\n",
        "                                facecolor='none')\n",
        "\n",
        "\n",
        "       # Draw the bounding box on top of the image\n",
        "       a.add_patch(rect)\n",
        "\n",
        "\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "JD45cRHgjbu-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the model and image and update the paths"
      ],
      "metadata": {
        "id": "akuwhaw3EQT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH1 = \"/content/TheOGTeam/Models/WeaponDetection_10_resnet.pt\"\n",
        "MODEL_SAVE_PATH2 = \"/content/TheOGTeam/Models/mobilenet_10.pt\"\n",
        "MODEL_SAVE_PATH3 = \"/content/TheOGTeam/Models/mobilenet_20.pt\"\n",
        "MODEL_SAVE_PATH4 = \"/content/TheOGTeam/Models/WeaponDetection_10_resnet2.0.pt\"\n",
        "\n",
        "model=torch.load(MODEL_SAVE_PATH2)\n",
        "test_path = \"/content/TheOGTeam/dataset/test/images/67fcce43-312_jpeg_jpg.rf.250e1320bc7ee7704df530b952e8f968.jpg\"\n",
        "# test_path = \"/content/dataset/test/images/FILE280_JPG_jpg.rf.0aabbe6284c929065e46cd54c8851558.jpg\"\n",
        "# test_path = \"/content/dataset/test/images/PUBGGunsInRealLife-06791_jpg.rf.068f5467a04fd696475901faccad0781.jpg\"\n",
        "test_data = load_test_img(test_path)\n",
        "model.eval()\n",
        "outputs = model([test_data])\n",
        "outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n",
        "\n",
        "nms_prediction = apply_nms(outputs[0], iou_thresh=0.7)\n",
        "\n",
        "plot_img_bbox(torch_to_pil(test_data), nms_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "olf3Wv2yjqSV",
        "outputId": "9b3ed8e9-04db-411f-c61f-4c23e7e07db5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-215137db21a0>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# test_path = \"/content/dataset/test/images/FILE280_JPG_jpg.rf.0aabbe6284c929065e46cd54c8851558.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test_path = \"/content/dataset/test/images/PUBGGunsInRealLife-06791_jpg.rf.068f5467a04fd696475901faccad0781.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-495a9c66a7d8>\u001b[0m in \u001b[0;36mload_test_img\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_test_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mimg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mimg_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_rgb\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}