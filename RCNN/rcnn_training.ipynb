{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvbasrRmaK6Y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy.core.defchararray import join, mod\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import os\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from torch._C import device\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, fasterrcnn_mobilenet_v3_large_fpn,fasterrcnn_resnet50_fpn_v2\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from PIL import Image\n",
        "from torchvision import transforms as torchtrans\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHElOro3jm4X"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3_VIspzduK-"
      },
      "outputs": [],
      "source": [
        "##Hyper Parameters##\n",
        "batch_size=2\n",
        "num_classes=2\n",
        "num_epoch = 10\n",
        "lr = 0.01\n",
        "momentum = 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BXNFaS8jHF0"
      },
      "source": [
        "#**Data Preprocessing** **bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload dataset and change the train paths"
      ],
      "metadata": {
        "id": "hNAuz-bFEkpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8Oz_Tg4bDQN"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = '/content/dataset/train/images'\n",
        "TRAIN_LABELS_PATH = '/content/dataset/train/rcnn_labels'\n",
        "VAL_PATH = '/content/dataset/valid/images'\n",
        "VAL_LABEL_PATH = '/content/dataset/valid/labels'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkPsRxCcaMOs"
      },
      "outputs": [],
      "source": [
        "class Images(Dataset):\n",
        "    def __init__(self,imgs_path,labels_path):\n",
        "\n",
        "        self.imgs_path = imgs_path\n",
        "        self.labels_path = labels_path\n",
        "        self.img_name = [img for img in sorted(os.listdir(self.imgs_path))]\n",
        "        self.label_name = [label for label in sorted(os.listdir(self.labels_path))]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        image_path = os.path.join(self.imgs_path,str(self.img_name[idx]))\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        img_res = img_rgb/255\n",
        "        img_res = torch.as_tensor(img_res).to(device)\n",
        "        img_res = img_res.permute(2, 0, 1)\n",
        "\n",
        "        label_name = self.img_name[idx][:-3] + \"txt\"\n",
        "        label_path = os.path.join(self.labels_path,str(label_name))\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            l_count = int(label_file.readline())\n",
        "            box = []\n",
        "            for i in range(l_count):\n",
        "                box.append(list(map(int, label_file.readline().split())))\n",
        "\n",
        "        target={}\n",
        "        target[\"boxes\"] = torch.as_tensor(box).to(device)\n",
        "        area = []\n",
        "        for i in range(len(box)):\n",
        "\n",
        "            a = (box[i][2] - box[i][0]) * (box[i][3] - box[i][1])\n",
        "            area.append(a)\n",
        "        target[\"area\"] = torch.as_tensor(area).to(device)\n",
        "        labels = []\n",
        "        for i in range(len(box)):\n",
        "            labels.append(1)\n",
        "\n",
        "        target[\"image_id\"] = torch.as_tensor([idx]).to(device)\n",
        "        target[\"labels\"] = torch.as_tensor(labels, dtype = torch.int64).to(device)\n",
        "\n",
        "\n",
        "        return img_res,target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_name)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-mPeUOZfGlc"
      },
      "outputs": [],
      "source": [
        "train_data = Images(TRAIN_PATH, TRAIN_LABELS_PATH)\n",
        "val_data = Images(VAL_PATH, VAL_LABEL_PATH)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
        "                       shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTcGHXDjlQkN"
      },
      "source": [
        "# **Creating the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpRVRZ3l2ce"
      },
      "source": [
        "Select the model to train by uncommenting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMfJJHGpoXWg"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "  def __init__(self,num_classes,epochs=30,lr=0.01, momentum=0.9):\n",
        "    # creating faster rcnn model\n",
        "    # fasterrcnn_resnet50_fpn, fasterrcnn_mobilenet_v3_large_fpn,fasterrcnn_resnet50_fpn_v2\n",
        "    # Uncomment any line one line\n",
        "\n",
        "    # model = fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
        "    # model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "    # model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
        "        in_features, num_classes)\n",
        "    model.to(device)\n",
        "    self.model = model\n",
        "    self.train_losses = []\n",
        "    self.valid_losses = []\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr\n",
        "    self.momentum = momentum\n",
        "\n",
        "  def train(self,train_data,val_data):\n",
        "    param = [param for param in self.model.parameters() if param.requires_grad]\n",
        "\n",
        "    optimizer = torch.optim.SGD(param,lr=self.lr,momentum=self.momentum)\n",
        "    best_val = 99999\n",
        "    for epoch in range(self.epochs):\n",
        "      tot_loss = 0\n",
        "      self.model.train()\n",
        "      for img, target in train_data:\n",
        "          loss_dict = self.model(img, target)\n",
        "          loss = sum(loss for loss in loss_dict.values())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          tot_loss += loss\n",
        "      print(\"eppch:{},train_loss:{}\".format(epoch, tot_loss))\n",
        "\n",
        "  def save(self,file_path):\n",
        "    torch.save(self.model, file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y5-ATohltRu"
      },
      "source": [
        "# **Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVBDjWHGl1g1"
      },
      "outputs": [],
      "source": [
        "model = Model(2,num_epoch,lr,momentum)\n",
        "model.train(train_loader,val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vii5wxUNqfCu"
      },
      "outputs": [],
      "source": [
        "# saving model into colab\n",
        "VERSION = '1'\n",
        "MODEL_SAVE_PATH = './WeaponDetection'+ VERSION + \".pt\"\n",
        "model.save(MODEL_SAVE_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}