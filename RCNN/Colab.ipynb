{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hvbasrRmaK6Y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy.core.defchararray import join, mod\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import os\n",
        "import torch\n",
        "from torch._C import device\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from PIL import Image\n",
        "from torchvision import transforms as torchtrans\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "VHElOro3jm4X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Hyper Parameters##\n",
        "batch_size=5\n",
        "num_classes=2\n",
        "num_epoch = 10\n",
        "lr = 0.01\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "S3_VIspzduK-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Preprocessing** **bold text**"
      ],
      "metadata": {
        "id": "7BXNFaS8jHF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = './drive/MyDrive/Colab Notebooks/input/Images'\n",
        "LABELS_PATH = './drive/MyDrive/Colab Notebooks/input/Labels'\n",
        "VERSION = '1'\n",
        "MODEL_SAVE_PATH = './WeaponDetection'+ VERSION + \".pt\""
      ],
      "metadata": {
        "id": "z8Oz_Tg4bDQN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzJ2j5IHAlxd",
        "outputId": "8cba3747-0f3f-4900-a4e0-2b23bc7a3fd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Images(Dataset):\n",
        "    def __init__(self,imgs_path,labels_path):\n",
        "\n",
        "        self.imgs_path = imgs_path\n",
        "        self.labels_path = labels_path\n",
        "        self.img_name = [img for img in sorted(os.listdir(self.imgs_path))]\n",
        "        self.label_name = [label for label in sorted(os.listdir(self.labels_path))]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        image_path = os.path.join(self.imgs_path,str(self.img_name[idx]))\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        img_res = img_rgb/255\n",
        "        img_res = torch.as_tensor(img_res).to(device)\n",
        "        img_res = img_res.permute(2, 0, 1)\n",
        "\n",
        "        label_name = self.img_name[idx][:-4] + \"txt\"\n",
        "        label_path = os.path.join(self.labels_path,str(label_name))\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            l_count = int(label_file.readline())\n",
        "            box = []\n",
        "            for i in range(l_count):\n",
        "                box.append(list(map(int, label_file.readline().split())))\n",
        "\n",
        "        target={}\n",
        "        target[\"boxes\"] = torch.as_tensor(box).to(device)\n",
        "        area = []\n",
        "        for i in range(len(box)):\n",
        "\n",
        "            a = (box[i][2] - box[i][0]) * (box[i][3] - box[i][1])\n",
        "            area.append(a)\n",
        "        target[\"area\"] = torch.as_tensor(area).to(device)\n",
        "        labels = []\n",
        "        for i in range(len(box)):\n",
        "            labels.append(1)\n",
        "\n",
        "        target[\"image_id\"] = torch.as_tensor([idx]).to(device)\n",
        "        target[\"labels\"] = torch.as_tensor(labels, dtype = torch.int64).to(device)\n",
        "\n",
        "\n",
        "        return img_res,target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_name)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "PkPsRxCcaMOs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gun_data = Images(IMAGES_PATH, LABELS_PATH)\n",
        "train_data = DataLoader(gun_data, batch_size=5,\n",
        "                       shuffle=True, num_workers=0, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "o-mPeUOZfGlc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the Model**"
      ],
      "metadata": {
        "id": "XTcGHXDjlQkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zGpRVRZ3l2ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "  def __init__(self,num_classes,epochs=30,lr=0.01, momentum=0.9):\n",
        "    #creating faster rcnn model\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
        "        in_features, num_classes)\n",
        "    model.to(device)\n",
        "    self.model = model\n",
        "\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr\n",
        "    self.momentum = momentum\n",
        "\n",
        "  def train(self,train_data):\n",
        "    param = [param for param in self.model.parameters() if param.requires_grad]\n",
        "\n",
        "    optimizer = torch.optim.SGD(param,lr=self.lr,momentum=self.momentum)\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      tot_loss = 0\n",
        "      self.model.train()\n",
        "      for img, target in train_data:\n",
        "          loss_dict = self.model(img, target)\n",
        "          loss = sum(loss for loss in loss_dict.values())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          tot_loss += loss\n",
        "      print(\"eppch:{},loss:{}\".format(epoch, tot_loss))\n",
        "\n",
        "  def save(self,file_path):\n",
        "    torch.save(self.model, file_path)\n"
      ],
      "metadata": {
        "id": "sMfJJHGpoXWg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the model**"
      ],
      "metadata": {
        "id": "3Y5-ATohltRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(2,num_epoch,lr,momentum)\n",
        "model.train(train_data)\n",
        "model.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVBDjWHGl1g1",
        "outputId": "4ed3be86-0edb-4260-da58-58f8ed7b354e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eppch:0,loss:16.60452651977539\n",
            "eppch:1,loss:11.904146194458008\n",
            "eppch:2,loss:8.87230110168457\n",
            "eppch:3,loss:7.0211920738220215\n",
            "eppch:4,loss:6.050671100616455\n",
            "eppch:5,loss:5.6785664558410645\n",
            "eppch:6,loss:4.997640609741211\n",
            "eppch:7,loss:4.763161659240723\n",
            "eppch:8,loss:4.346904754638672\n"
          ]
        }
      ]
    }
  ]
}